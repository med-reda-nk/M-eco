==========================
Approaches and Models Used
==========================

This project focuses exclusively on deep learning models tailored for time series forecasting. The models employed are:

RNN (Recurrent Neural Network)
------------------------------
The foundational sequence model capturing temporal dependencies by maintaining internal states, suitable for simpler sequence patterns.

LSTM (Long Short-Term Memory)
-----------------------------
An advanced RNN variant that addresses the vanishing gradient problem and captures long-term dependencies in sequences effectively.

BiLSTM (Bidirectional LSTM)
---------------------------
Processes input sequences in both forward and backward directions, improving context awareness and forecasting accuracy.

LSTM-CNN Hybrid
---------------
Combines convolutional layers for feature extraction with LSTM layers to model temporal relationships, capturing local patterns and long-term dependencies.

GRU (Gated Recurrent Unit)
--------------------------
A streamlined variant of LSTM with fewer parameters, providing efficient sequence modeling with comparable performance.

TCN (Temporal Convolutional Network)
------------------------------------
Employs causal convolutions with dilation to model long-range temporal dependencies efficiently and with parallel computations.

Transformer
-----------
Uses self-attention mechanisms to capture complex dependencies and relationships in sequences without relying on recurrent structures.

Optimization Strategy
---------------------
Each deep learning architecture was carefully tuned using *Optuna* hyperparameter optimization with cross-validation to find the best settings per economic indicator.
